{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv('train_data.csv')\n",
    "train_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw[train_data_raw['minimum_nights'] == train_data_raw['minimum_nights'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw[train_data_raw['number_of_reviews'] == train_data_raw['number_of_reviews'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw[train_data_raw['reviews_per_month'] == train_data_raw['reviews_per_month'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw[train_data_raw['calculated_host_listings_count'] == train_data_raw['calculated_host_listings_count'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw = pd.read_csv('test_data.csv')\n",
    "test_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.dropna(axis=\"rows\")\n",
    "\n",
    "    df = df.drop(['id', 'name', 'host_id', 'host_name'], axis=\"columns\")\n",
    "\n",
    "    df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "    df['last_review'] = max(df['last_review'])-df['last_review']\n",
    "    df['last_review'] = df['last_review'].dt.days\n",
    "\n",
    "    ohe = pd.get_dummies(df[{'neighbourhood_group','room_type'}])\n",
    "    df = pd.concat([df, ohe], axis='columns')\n",
    "    df = df.drop(['room_type','neighbourhood_group'], axis='columns')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocess(train_data_raw)\n",
    "test_data = preprocess(test_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.scatterplot(train_data_raw.longitude, train_data_raw.latitude,\n",
    "                hue=train_data_raw.neighbourhood_group)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data['minimum_nights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data['number_of_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data['reviews_per_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data['calculated_host_listings_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_data.corr(method='kendall')\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr, annot=True, center=0, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[['latitude', 'longitude', 'calculated_host_listings_count', 'neighbourhood_group_Bronx', 'neighbourhood_group_Brooklyn',\n",
    "       'neighbourhood_group_Manhattan', 'neighbourhood_group_Queens', 'room_type_Entire home/apt', 'room_type_Private room']]\n",
    "Y = train_data['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, Y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    print('__________________________________')\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train,y_train)\n",
    "test_pred = lin_reg.predict(X_test)\n",
    "train_pred = lin_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Regression - Random Sample Consensus - RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "model = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.1, \n",
    "              precompute=True, \n",
    "              positive=True, \n",
    "              selection='random',\n",
    "              random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "\n",
    "X_train_2_d = poly_reg.fit_transform(X_train)\n",
    "X_test_2_d = poly_reg.transform(X_test)\n",
    "\n",
    "lin_reg = LinearRegression(normalize=True)\n",
    "lin_reg.fit(X_train_2_d,y_train)\n",
    "\n",
    "test_pred = lin_reg.predict(X_test_2_d)\n",
    "train_pred = lin_reg.predict(X_train_2_d)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Polynomail Regression\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = sgd_reg.predict(X_test)\n",
    "train_pred = sgd_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = rf_reg.predict(X_test)\n",
    "train_pred = rf_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\n",
    "svm_reg.fit(X_train, y_train)\n",
    "\n",
    "test_pred = svm_reg.predict(X_test)\n",
    "train_pred = svm_reg.predict(X_train)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y_test, test_pred)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(y_test - test_pred, fill=True)\n",
    "plt.xlabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.set_index('Model', inplace=True)\n",
    "results_df['R2 Square'].plot(kind='barh', figsize=(12, 8))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
